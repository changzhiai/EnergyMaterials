{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Heat of Formation\n",
    "\n",
    "In this exercise we will try to predict the heat of formation (HOF) of cubic oxoperovskites, based on data that we can look up. We have generated such a table for you in the file `periodic_table_groups.csv`, which can be loaded as a Pandas data frame, as done below.\n",
    "\n",
    "We also load the database by Ivano to get our answers, so we can train a machine.\n",
    "\n",
    "If you don't have the data base, use the command below to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://cmr.fysik.dtu.dk/_downloads/a8829848dc5806fc8adea6974bed0e6d/cubic_perovskites.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ase.db import connect\n",
    "import pandas as pd\n",
    "con = connect('cubic_perovskites.db')\n",
    "pt = pd.read_csv('periodic_table_groups.csv', index_col='Symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Inspect the data frame, to get an understanding what it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can construct a feature vector from this table. In the cell below we construct a small feature vector, which contains the atomic number, Z, of the A and B ions in the perovskite, ABO$_3$, as well as the period and group in the periodic table.\n",
    "\n",
    "The idea with the period and group, is that metals close to eachother in the periodic table will have similar behaviors, and thus the euclidean distance of (period, group) provides a similarity measure between metals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_fingerprint(row):\n",
    "    A = row.A_ion\n",
    "    B = row.B_ion\n",
    "    x = []\n",
    "    \n",
    "    features = ['AtomicNumber', 'Period', 'Group']  # Initial features to include\n",
    "    \n",
    "    # Construct feature vector\n",
    "    symbols = [A, B]\n",
    "    x = []\n",
    "    for feat in features:\n",
    "        for sym in symbols:\n",
    "            x.append(pt.loc[sym, feat])\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We now need to construct the input feature matrix, X, and the target vector with our correct answer, Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "selection = {'combination': 'ABO3'}  # Our selection from the database\n",
    "n_samples = con.count(**selection)\n",
    "def make_X():\n",
    "    '''Make input matrix using ids from database'''\n",
    "    n_features = len(make_fingerprint(con.get(id=1)))  # Length of input vector\n",
    "    X = np.zeros((n_samples, n_features))\n",
    "    \n",
    "    for ii, row in enumerate(con.select(**selection)):\n",
    "        X[ii, :] = make_fingerprint(row)\n",
    "    return X\n",
    "\n",
    "def make_Y():  \n",
    "    Y = np.zeros(n_samples)\n",
    "    for ii, row in enumerate(con.select(**selection)):\n",
    "        Y[ii] = row.heat_of_formation_all\n",
    "    return Y\n",
    "\n",
    "X = make_X()\n",
    "Y = make_Y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can then take a part of our data, train a model on that piece of data, and see how well we perform on the remainder. The below provides an auxillary function for performing this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "def make_comparison_plot(X, y, model):\n",
    "    X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    ybar = model.predict(X_test)\n",
    "    \n",
    "    n_train, n_test = len(y_train), len(y_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, ybar)\n",
    "    mae = mean_absolute_error(y_test, ybar)\n",
    "    \n",
    "    ymax = np.array((y_test, ybar)).max() + 0.1\n",
    "    ymin = np.array((y_test, ybar)).min() - 0.1\n",
    "    plt.scatter(ybar, y_test, zorder=0)\n",
    "    plt.xlim(ymin, ymax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.plot([ymin, ymax], [ymin, ymax], 'k--', zorder=1)\n",
    "    plt.xlabel('Predicted HOF [eV]')\n",
    "    plt.ylabel('Actual HOF [eV]')\n",
    "    plt.title('MAE: {:.3f} eV, $r^2$ score: {:.3f}, trained on: {:d}, tested on: {:d}'.format(mae, r2, n_train, n_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's try and train a linear model on the data, and see how well we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "linear = linear_model.LinearRegression()\n",
    "make_comparison_plot(X, Y, linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Not very well - it's quite clear, that we cannot predict the HOF from simple table data using a linear model. So we have 2 choices:\n",
    "\n",
    "1. Use a more complex model\n",
    "2. Include more complex data\n",
    "\n",
    "Let's first try and use a more complex model. Train a kernel ridge regression (KRR) model with Gaussian (RBF) kernel from the sklearn package, and compare it with the linear model. Does it improve anything? See http://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Also try modifying the hyperparameters, `alpha` and `gamma`, and see if you can improve it further. One option for doing this is using the [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) function.\n",
    "\n",
    "Hopefully, you should find that you can drastically improve the accuracy we obtain. Now you should try and include more data from the table we provided you with, and see how much we gain. Can you identify which parameters are most important to our model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "name": "HOF_student.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
